{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8184a9f3",
   "metadata": {},
   "source": [
    "# Treinamento Multi-Modelo (Estratégia Delta)\n",
    "\n",
    "**Contexto:**\n",
    "Diferentes carteiras de crédito reagem de forma diferente à economia. A inadimplência Rural depende de safra; a PJ depende do PIB; a PF depende do desemprego. Por isso, treinaremos **modelos especialistas** para cada segmento.\n",
    "\n",
    "**Estratégia Matemática (Delta Learning):**\n",
    "Em vez de tentar prever o valor absoluto (ex: Inadimplência será 3.5%), vamos treinar o modelo para prever a **VARIAÇÃO (Delta)** em relação ao mês anterior.\n",
    "\n",
    "$$\\text{Previsão}_{t} = \\text{Valor Real}_{t-1} + \\Delta_{\\text{Predito}}$$\n",
    "\n",
    "Isso torna o sistema muito mais sensível a mudanças de tendência de curto prazo e corrige o viés de escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59105afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base de dados carregada com sucesso. Shape: (120, 50)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Importação e Configuração ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuração Visual\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Definição de Caminhos (Pathlib garante compatibilidade Windows/Mac/Linux)\n",
    "path_data = Path(\"../data/processed/df_modelagem_v3.csv\")\n",
    "path_models = Path(\"../models/\")\n",
    "path_models.mkdir(parents=True, exist_ok=True) # Cria a pasta models se não existir\n",
    "\n",
    "# Carga dos Dados\n",
    "if path_data.exists():\n",
    "    df = pd.read_csv(path_data, index_col=\"data\", parse_dates=True)\n",
    "    print(f\"✅ Base de dados carregada com sucesso. Shape: {df.shape}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"ERRO CRÍTICO: Arquivo 'df_modelagem_v3.csv' não encontrado. Execute o notebook 03 primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddaac6a",
   "metadata": {},
   "source": [
    "# Definição dos Alvos (Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb172ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos que serão treinados: ['PF', 'PJ', 'Rural_PF', 'Rural_PJ']\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Definição dos Segmentos ---\n",
    "\n",
    "# Mapeamento: \"Nome Amigável do Modelo\" -> \"Coluna no DataFrame\"\n",
    "targets_potenciais = {\n",
    "    \"PF\": \"inad_pf_tot\",\n",
    "    \"PJ\": \"inad_pj_tot\",\n",
    "    \"Rural_PF\": \"inad_rd_pf_cr_rur_tot\",  \n",
    "    \"Rural_PJ\": \"inad_rd_pj_cr_rur_tot\"   \n",
    "}\n",
    "\n",
    "targets = {k: v for k, v in targets_potenciais.items() if v in df.columns}\n",
    "\n",
    "print(f\"Modelos que serão treinados: {list(targets.keys())}\")\n",
    "\n",
    "if len(targets) < len(targets_potenciais):\n",
    "    print(\"Aviso: Algumas colunas de inadimplência rural não foram encontradas e serão ignoradas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af979c9",
   "metadata": {},
   "source": [
    "## Pipeline de Treinamento em Loop\n",
    "\n",
    "Para cada segmento (PF, PJ, Rural), o código abaixo vai:\n",
    "1.  **Calcular o Delta:** Criar a variável alvo (Diferença mês a mês).\n",
    "2.  **Isolar Variáveis:** Remover vazamento de dados (outras inadimplências).\n",
    "3.  **Feature Engineering:** Adicionar o valor do mês anterior como input (Inércia).\n",
    "4.  **Treinar:** Random Forest Regressor.\n",
    "5.  **Serializar:** Salvar Modelo, Scaler e Metadados para o App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014b48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESSAMENTO EM LOTE ---\n",
      "\n",
      "Treinando Modelo: PF (Alvo: inad_pf_tot)...\n",
      "Modelo salvo! | Último Valor Real: 3.54% em 2025-12-01\n",
      "\n",
      "Treinando Modelo: PJ (Alvo: inad_pj_tot)...\n",
      "Modelo salvo! | Último Valor Real: 2.03% em 2025-12-01\n",
      "\n",
      "Treinando Modelo: Rural_PF (Alvo: inad_rd_pf_cr_rur_tot)...\n",
      "Modelo salvo! | Último Valor Real: 2.28% em 2025-12-01\n",
      "\n",
      "Treinando Modelo: Rural_PJ (Alvo: inad_rd_pj_cr_rur_tot)...\n",
      "Modelo salvo! | Último Valor Real: 0.32% em 2025-12-01\n",
      "\n",
      "--- PROCESSO CONCLUÍDO ---\n",
      "Todos os arquivos foram salvos em: c:\\Users\\pedro\\projeto_inadimplencia\\notebooks\\..\\models\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Loop de Treinamento e Exportação ---\n",
    "\n",
    "print(\"--- INICIANDO PROCESSAMENTO EM LOTE ---\")\n",
    "\n",
    "cols_leakage_base = [c for c in df.columns if c.startswith(\"inad_\")]\n",
    "\n",
    "for nome_modelo, target_col in targets.items():\n",
    "    print(f\"\\nTreinando Modelo: {nome_modelo} (Alvo: {target_col})...\")\n",
    "    \n",
    "    # A. Preparação do Dataset Temporário\n",
    "    df_train = df.copy()\n",
    "    \n",
    "    # B. Engenharia do Alvo (Target Engineering)\n",
    "    df_train[\"target_delta\"] = df_train[target_col].diff()\n",
    "    \n",
    "    # C. Engenharia de Features (Feature Engineering)\n",
    "    df_train[\"valor_anterior\"] = df_train[target_col].shift(1)\n",
    "    df_train = df_train.dropna()\n",
    "    \n",
    "    # D. Definição de X (Features) e y (Target)\n",
    "    y = df_train[\"target_delta\"]\n",
    "    \n",
    "    # Lógica de Limpeza do X:\n",
    "    X = df_train.drop(columns=cols_leakage_base + [\"target_delta\"])\n",
    "    X[\"inad_anterior\"] = df_train[\"valor_anterior\"]\n",
    "    \n",
    "    # Garantia de Dummies\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    # E. Padronização (Scaling)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # F. Treinamento (Fit)\n",
    "    # Usamos max_depth=10 para evitar overfitting excessivo em dados ruidosos\n",
    "    model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "    model.fit(X_scaled, y)\n",
    "    \n",
    "    # --- G. SALVAMENTO DOS ARTEFATOS ---\n",
    "    \n",
    "    # 1. O Modelo\n",
    "    joblib.dump(model, path_models / f\"model_{nome_modelo}_multimodelo.pkl\")\n",
    "    \n",
    "    # 2. O Scaler\n",
    "    joblib.dump(scaler, path_models / f\"scaler_{nome_modelo}_multimodelo.pkl\")\n",
    "    \n",
    "    # 3. Lista de Colunas\n",
    "    pd.DataFrame(columns=X.columns).to_csv(path_models / f\"columns_{nome_modelo}_multimodelo.csv\", index=False)\n",
    "    \n",
    "    # 4. Metadados de \"Ancoragem\"\n",
    "    ultimo_dado = {\n",
    "        \"data_referencia\": df.index[-1],\n",
    "        \"valor_ultimo_real\": df.iloc[-1][target_col],\n",
    "        \"X_ultimo_real\": X.iloc[-1].to_dict()\n",
    "    }\n",
    "    joblib.dump(ultimo_dado, path_models / f\"meta_{nome_modelo}.pkl\")\n",
    "    \n",
    "    print(f\"Modelo salvo! | Último Valor Real: {ultimo_dado['valor_ultimo_real']:.2f}% em {ultimo_dado['data_referencia'].date()}\")\n",
    "\n",
    "print(\"\\n--- PROCESSO CONCLUÍDO ---\")\n",
    "print(f\"Todos os arquivos foram salvos em: {path_models.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72949558",
   "metadata": {},
   "source": [
    "## Próximos Passos\n",
    "\n",
    "Com a pasta `models/` criada com as informações que o Streamlit precisa:\n",
    "1.  **`model_*.pkl`**: O cérebro que prevê a variação.\n",
    "2.  **`scaler_*.pkl`**: A calculadora que ajusta a escala dos dados.\n",
    "3.  **`meta_*.pkl`**: O ponto de partida (última inadimplência conhecida).\n",
    "\n",
    "Próxima etapa: construir o arquivo `app_1.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
